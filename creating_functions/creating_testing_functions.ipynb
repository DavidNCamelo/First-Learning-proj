{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59fe58a8",
   "metadata": {},
   "source": [
    "# Learning Functions creation\n",
    "\n",
    "This Jupyuter notebook is part of a Master assingments. In this case I'll \"invent\" functions to practice how to work with python by functional programming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dba8b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I made this function years ago to simplify calculations in a personal projects\n",
    "\n",
    "# Required libraries\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# To simplify the process of grouping the Passenger and Dispatch variables, the following variable will be created:\n",
    "def grupo_por_columna(dt, columna_agrupada):\n",
    "    #   Group data in sum agregation\n",
    "    agrupacion = dt.groupby(columna_agrupada).agg({'PASAJEROS': 'sum', 'DESPACHOS': 'sum'}).reset_index()\n",
    "    return agrupacion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8890b6d7",
   "metadata": {},
   "source": [
    "### Using grupo_por_columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d41aaf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MES-AÑO  PASAJEROS  DESPACHOS\n",
      "0  2019-01      55096       6062\n",
      "1  2019-02      19156       1466\n",
      "2  2019-03        110          3\n",
      "3  2019-04        895         55\n",
      "4  2019-05      32625       2923\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"Transporte Pasajeros 2019-2023.csv\")\n",
    "\n",
    "# Eg 1 groubing by just 'MES-AÑO'\n",
    "data['FECHA_DESPACHO'] = pd.to_datetime(data['FECHA_DESPACHO'])\n",
    "data['MES-AÑO'] = data['FECHA_DESPACHO'].dt.to_period('M')\n",
    "data_agrupada_mes = grupo_por_columna(data, 'MES-AÑO')\n",
    "\n",
    "print(data_agrupada_mes.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6ed421a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  DEPARTAMENTO_ORIGEN  PASAJEROS  DESPACHOS\n",
      "0           ANTIOQUIA   65995610    7011412\n",
      "1              ARAUCA      78547       9288\n",
      "2           ATLÁNTICO    9297180    1271075\n",
      "3        BOGOTÁ, D.C.   85434411   11923539\n",
      "4             BOLÍVAR   15215346    1751046\n",
      "5              BOYACÁ   37410265    4984071\n",
      "6              CALDAS   14036385    1705261\n",
      "7             CAQUETÁ    5687825     896045\n",
      "8            CASANARE    2986045     437678\n",
      "9               CAUCA   12296827    1092384\n"
     ]
    }
   ],
   "source": [
    "# Grouping by \"DEPARTEMENTO_ORIGEN\"\n",
    "tendencia_anual_por_departamento = grupo_por_columna(data, 'DEPARTAMENTO_ORIGEN')\n",
    "\n",
    "print(tendencia_anual_por_departamento.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fbc0a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CLASE_VEHICULO        NIVEL_SERVICIO  PASAJEROS  DESPACHOS\n",
      "0      AUTOMOVIL                BASICO    3310648    1063537\n",
      "1      AUTOMOVIL                  LUJO    4350753    1435932\n",
      "2      AUTOMOVIL  PREFERENCIAL DE LUJO        213         47\n",
      "3            BUS                BASICO   73567689    5893970\n",
      "4            BUS                  LUJO  174681848   17410473\n",
      "5            BUS  PREFERENCIAL DE LUJO     147240       5169\n",
      "6         BUSETA                BASICO   21286977    2725407\n",
      "7         BUSETA                  LUJO   26979582    4598104\n",
      "8         BUSETA  PREFERENCIAL DE LUJO      16426       1609\n",
      "9         CAMION                BASICO         12          3\n"
     ]
    }
   ],
   "source": [
    "# Grouping by \"CLASE_VEHICULO\" and \"NIVEL_SERVICIO\"\n",
    "data_por_vehiculo = grupo_por_columna(data, ['CLASE_VEHICULO', 'NIVEL_SERVICIO'])\n",
    "\n",
    "print(data_por_vehiculo.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b109f55",
   "metadata": {},
   "source": [
    "## Function 2\n",
    "Title Case words in spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86ecdaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_case_spanish(s: str) -> str:\n",
    "    \"\"\"\n",
    "    Apply 'Title Case' ignoring common prepositions in spanish\n",
    "    (ej. 'de', 'la', 'y', 'en') except if these are at beging of a phrase.\n",
    "    \"\"\"\n",
    "    small_words = {\n",
    "        \"y\",\"a\",\"de\",\"del\",\"la\",\"el\",\"las\",\"los\",\"en\",\"con\",\"por\",\"para\",\"sin\",\n",
    "        \"sobre\",\"entre\",\"un\",\"una\",\"unos\",\"unas\",\"al\",\"lo\"\n",
    "    }\n",
    "    words = s.split()\n",
    "    out = []\n",
    "    for i, w in enumerate(words):\n",
    "        lw = w.lower()\n",
    "        if i != 0 and lw in small_words:\n",
    "            out.append(lw)\n",
    "        else:\n",
    "            out.append(w.capitalize())\n",
    "    return \" \".join(out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b82fd8",
   "metadata": {},
   "source": [
    "### Using title_case_spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fa8132b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ej1: \n",
      "La Casa de los Dibujos\n",
      "Ej2: \n",
      "Harry Potter y la Orden del Fénix\n",
      "Ej1: \n",
      "Desde Mi Cielo - Mago de Oz\n"
     ]
    }
   ],
   "source": [
    "print('Ej1: ')\n",
    "print(title_case_spanish(\"la casa de los dibujos\"))\n",
    "\n",
    "print('Ej2: ')\n",
    "print(title_case_spanish(\"harry potter y la orden del fénix\"))\n",
    "\n",
    "print('Ej1: ')\n",
    "print(title_case_spanish(\"desde mi cielo - mago de oz\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbca70e",
   "metadata": {},
   "source": [
    "# Function 3\n",
    "\n",
    "Show ISO codes and phone code for a given country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77240115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function sill required pandas because requires a .csv file\n",
    "\n",
    "def info_country(country):\n",
    "    \"\"\"\n",
    "    search a given country (by Spanish or English name) in the CSV file\n",
    "    and return its ISO2, ISO3, and PHONE_CODE.\n",
    "    \"\"\"\n",
    "    # Load file\n",
    "    info_file = pd.read_csv('paises.csv')\n",
    "\n",
    "    # Normalize content\n",
    "    country_lower = country.strip().lower()\n",
    "\n",
    "    # Look up by ESPAÑOL or ENGLISH\n",
    "    match = info_file[\n",
    "        (info_file[\"ESPAÑOL\"].str.lower() == country_lower) |\n",
    "        (info_file[\"ENGLISH\"].str.lower() == country_lower)\n",
    "    ]\n",
    "\n",
    "    if match.empty:\n",
    "        return {\"error\": f\"Country '{country}' not found.\"}\n",
    "\n",
    "    row = match.iloc[0]\n",
    "    return {\n",
    "        \"ESPAÑOL\": row[\"ESPAÑOL\"],\n",
    "        \"ENGLISH\": row[\"ENGLISH\"],\n",
    "        \"ISO2\": row[\"ISO2\"],\n",
    "        \"ISO3\": row[\"ISO3\"],\n",
    "        \"PHONE_CODE\": row[\"PHONE_CODE\"]\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f99384",
   "metadata": {},
   "source": [
    "### Using info_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ed4f98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ej1:\n",
      "{'ESPAÑOL': 'España', 'ENGLISH': 'Spain', 'ISO2': 'ES', 'ISO3': 'ESP', 'PHONE_CODE': '34'}\n",
      "Ej2:\n",
      "{'ESPAÑOL': 'Colombia', 'ENGLISH': 'Colombia', 'ISO2': 'CO', 'ISO3': 'COL', 'PHONE_CODE': '57'}\n",
      "Ej3:\n",
      "{'ESPAÑOL': 'México', 'ENGLISH': 'Mexico', 'ISO2': 'MX', 'ISO3': 'MEX', 'PHONE_CODE': '52'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Ej1:\")\n",
    "print(info_country('Spain'))\n",
    "\n",
    "print(\"Ej2:\")\n",
    "print(info_country('Colombia'))\n",
    "\n",
    "print(\"Ej3:\")\n",
    "print(info_country('México'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc74aeb",
   "metadata": {},
   "source": [
    "# Function 4\n",
    "\n",
    "Add placeholder for long lines, ideal for coding formating logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ec2d533",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringify_with_limit(obj, limit: int = 80, placeholder: str = '...') -> str:\n",
    "    \"\"\"\n",
    "    Conver objects to strings and trunc\n",
    "    `limit` characteres, adding a placeholder.\n",
    "    \"\"\"\n",
    "    s = str(obj)\n",
    "    if len(s) <= limit:\n",
    "        return s\n",
    "    cut = max(0, limit - len(placeholder))\n",
    "    return s[:cut] + placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09b83557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ej1: \n",
      "aaaaaaaaaaaaaaaaa...\n",
      "Ej2:\n",
      "About this point, there are missing v...\n",
      "Ej2:\n",
      "Creating som...\n"
     ]
    }
   ],
   "source": [
    "long = \"a\"*100\n",
    "print(\"Ej1: \")\n",
    "print(stringify_with_limit(long, limit=20))\n",
    "\n",
    "text = \"About this point, there are missing values in number of hospital beds column based on the total count rows in the table\"\n",
    "print(\"Ej2:\")\n",
    "print(stringify_with_limit(text, limit=40))\n",
    "\n",
    "text2 = \"Creating some dependent and independent variables \"\n",
    "print(\"Ej2:\")\n",
    "print(stringify_with_limit(text2, limit=15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9d8c37",
   "metadata": {},
   "source": [
    "# Function 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5bb9918f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Union\n",
    "\n",
    "def safe_divide(a: Union[int,float], b: Union[int,float],\n",
    "                default: Optional[Union[int,float]] = None,\n",
    "                rounding: Optional[int] = None) -> Optional[Union[int,float]]:\n",
    "    \"\"\"\n",
    "    Divides a / b, returning `default` if division by zero or invalid values.\n",
    "    If rounding is int, rounds the result to that number of decimal places.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        res = a / b\n",
    "    except Exception:\n",
    "        return default\n",
    "    if rounding is not None:\n",
    "        return round(res, rounding)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c554937",
   "metadata": {},
   "source": [
    "### Using safe_divide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06a7e54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ej1:\n",
      "2.5\n",
      "Ej2:\n",
      "inf\n",
      "Ej3: 3.33\n"
     ]
    }
   ],
   "source": [
    "print(\"Ej1:\")\n",
    "print(safe_divide(5, 2))\n",
    "\n",
    "print(\"Ej2:\")\n",
    "print(safe_divide(1, 0, default=float('inf')))\n",
    "\n",
    "print(f'Ej3: {safe_divide(10, 3, rounding=2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebeb2aa",
   "metadata": {},
   "source": [
    "# Function 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f49fdf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Any\n",
    "\n",
    "def chunk_list(lst: List[Any], n: int) -> List[List[Any]]:\n",
    "    \"\"\"\n",
    "    Splits a list into chunks of size n. The last chunk may be smaller.\n",
    "    Throws ValueError if n <= 0.\n",
    "    \"\"\"\n",
    "    if n <= 0:\n",
    "        raise ValueError(\"n debe ser > 0\")\n",
    "    return [lst[i:i+n] for i in range(0, len(lst), n)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c78cb31",
   "metadata": {},
   "source": [
    "### Using chunk_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "127c9cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ej1: [[0, 1, 2], [3, 4, 5], [6]]\n",
      "Ej2: [['a', 'b'], ['c', 'd']]\n",
      "Ej3: [[1, 2, 3]]\n"
     ]
    }
   ],
   "source": [
    "print(f'Ej1: {chunk_list(list(range(7)), 3)}')\n",
    "\n",
    "print(f'Ej2: {chunk_list([\"a\",\"b\",\"c\",\"d\"], 2)}')\n",
    "\n",
    "print(f'Ej3: {chunk_list([1,2,3], 5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0815078f",
   "metadata": {},
   "source": [
    "# Function 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c1e9c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any\n",
    "\n",
    "def flatten_dict(d: Dict[str, Any], parent_key: str = '', sep: str = '.') -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Flattens a dictionary nested within a dictionary with concatenated keys.\n",
    "    If it finds lists, it includes the index in the key: e.g. ‘items.0.name’.\n",
    "    \"\"\"\n",
    "    items = {}\n",
    "    for k, v in d.items():\n",
    "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.update(flatten_dict(v, new_key, sep=sep))\n",
    "        elif isinstance(v, list):\n",
    "            for i, elem in enumerate(v):\n",
    "                if isinstance(elem, dict):\n",
    "                    items.update(flatten_dict(elem, f\"{new_key}{sep}{i}\", sep=sep))\n",
    "                else:\n",
    "                    items[f\"{new_key}{sep}{i}\"] = elem\n",
    "        else:\n",
    "            items[new_key] = v\n",
    "    return items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e4a207",
   "metadata": {},
   "source": [
    "### Using flaten_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "929f322e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ej1: {'a': 1, 'b.c': 2, 'b.d.e': 3}\n",
      "{'Apple.0.Pineapple': 1, 'Apple.1.Banana': 2, 'Grape': 3}\n",
      "{'user.name': 'Ana', 'user.roles.0': 'admin', 'user.roles.1': 'user'}\n"
     ]
    }
   ],
   "source": [
    "d = {\"a\": 1, \"b\": {\"c\": 2, \"d\": {\"e\": 3}}}\n",
    "print(f'Ej1: {flatten_dict(d)}')\n",
    "\n",
    "fruits = {\"Apple\": [{\"Pineapple\": 1}, {\"Banana\": 2}], \"Grape\": 3}\n",
    "print(flatten_dict(fruits))\n",
    "\n",
    "data_user = {\"user\": {\"name\": \"Ana\", \"roles\": [\"admin\",\"user\"]}}\n",
    "print(flatten_dict(data_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f38c072",
   "metadata": {},
   "source": [
    "# Function 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d60fce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Any\n",
    "\n",
    "def dedupe_list_preserve_order(lst: List[Any]) -> List[Any]:\n",
    "    \"\"\"\n",
    "    Removes duplicates while preserving the order of first appearance.\n",
    "    Works with hashable elements; for non-hashable elements, adaptation would be required.\n",
    "    \"\"\"\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for x in lst:\n",
    "        if x not in seen:\n",
    "            seen.add(x)\n",
    "            out.append(x)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76633d3b",
   "metadata": {},
   "source": [
    "### Using dedupe_list_preserve_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "626fafab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ej1: [1, 2, 3, 4]\n",
      "Ej2: ['Pear', 'Apple', 'Watermelon', 'Pineapple', 'Banana']\n",
      "Ej3: [1, 2, 'Apple', 'Watermelon', 4]\n"
     ]
    }
   ],
   "source": [
    "print(f'Ej1: {dedupe_list_preserve_order([1,2,2,3,1,4])}')\n",
    "print(f'Ej2: {dedupe_list_preserve_order([\"Pear\",\"Apple\",\"Watermelon\",\"Pineapple\",\"Pear\",\"Banana\", \"Apple\", \"Pear\"])}')\n",
    "print(f'Ej3: {dedupe_list_preserve_order([1,2,2,\"Apple\",\"Watermelon\",4])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dae10b1",
   "metadata": {},
   "source": [
    "# Function 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a121ff3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List, Union\n",
    "\n",
    "def extract_numbers(s: str, floats: bool = True) -> List[Union[int, float]]:\n",
    "    \"\"\"\n",
    "    Extract numbers from a string. If floats=True, return decimals where appropriate;\n",
    "    otherwise, return all as integers (treating decimal points as separators).\n",
    "    \"\"\"\n",
    "    pattern = r'[-+]?\\d*\\.\\d+|[-+]?\\d+'\n",
    "    matches = re.findall(pattern, s)\n",
    "    result = []\n",
    "    for m in matches:\n",
    "        if floats and ('.' in m or 'e' in m.lower()):\n",
    "            result.append(float(m))\n",
    "        else:\n",
    "            # si floats==False forzamos int (posible pérdida de información)\n",
    "            if '.' in m:\n",
    "                result.append(float(m) if floats else int(float(m)))\n",
    "            else:\n",
    "                result.append(int(m))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ab0cd1",
   "metadata": {},
   "source": [
    "### Using extract_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "80a8dad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ej1: [2024, 3.5, -2]\n",
      "Ej2: [0, 9478651, 63177087, 0, 0.15003304916543556]\n",
      "Ej3: [2019, -3, 3, 110]\n"
     ]
    }
   ],
   "source": [
    "print(f'Ej1: {extract_numbers(\"En 2024 hubo 3.5% y -2 casos\")}')\n",
    "\n",
    "print(f'Ej2: {extract_numbers(\"Cantidad de viajes con 0 parasajeros 9478651 Tamaño total del conjunto 63177087 razón pasajeros 0 sobre total 0.15003304916543556\")}')\n",
    "\n",
    "print(f'Ej3: {extract_numbers(\"Mes con el mínimo general: 2019-03, Despachos: 3, Pasajeros: 110\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2654e9d0",
   "metadata": {},
   "source": [
    "# Function 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f50784ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalize_whitespace(s: str, case: str = 'preserve') -> str:\n",
    "    \"\"\"\n",
    "    Remove extra spaces (including line breaks) leaving a single space between words\n",
    "    and no leading/trailing spaces.\n",
    "\n",
    "    `case` parameter:\n",
    "      - ‘preserve’ : leaves the text case as is (default)\n",
    "      - ‘lower’    : returns everything in lowercase\n",
    "      - ‘title’: applies Title Case (capitalize each word)\n",
    "      - ‘sentence’: sentence case (first letter of each sentence capitalized, rest lowercase)\n",
    "\n",
    "    Note: ‘sentence’ understands sentences separated by ‘.’, ‘!’, or ‘?’ followed by a space.\n",
    "    \"\"\"\n",
    "    cleaned = re.sub(r'\\s+', ' ', s.strip())\n",
    "\n",
    "    if case == 'preserve':\n",
    "        return cleaned\n",
    "    if case == 'lower':\n",
    "        return cleaned.lower()\n",
    "    if case == 'title':\n",
    "        return cleaned.title()\n",
    "    if case == 'sentence':\n",
    "        # convert everything to lowercase and then capitalize the first letter\n",
    "        s2 = cleaned.lower()\n",
    "        pattern = re.compile(r'(^|(?<=[\\.\\!\\?]\\s))([a-záéíóúüñ])', flags=re.IGNORECASE)\n",
    "        return pattern.sub(lambda m: m.group(1) + m.group(2).upper(), s2)\n",
    "\n",
    "    raise ValueError(\"case must be one of: 'preserve','lower','title','sentence'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1479e2d1",
   "metadata": {},
   "source": [
    "### Using normalize_whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "04f1b6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ej1 preserve: Creando PRUEBAS esto es prueba\n",
      "Ej1 lower:    creando pruebas esto es prueba\n",
      "Ej1 title:    Creando Pruebas Esto Es Prueba\n",
      "Ej1 sentence: Creando pruebas esto es prueba\n",
      "Ej2 preserve: Clima caluroso llamen a EmErGeNcias\n",
      "Ej2 lower:    clima caluroso llamen a emergencias\n",
      "Ej2 sentence: Clima caluroso llamen a emergencias\n",
      "Ej3 preserve: welcome to redistribute livig N\n",
      "Ej3 lower:    welcome to redistribute livig n\n",
      "Ej3 title:    Welcome To Redistribute Livig N\n"
     ]
    }
   ],
   "source": [
    "s = \"  Creando PRUEBAS \\n esto   es   prueba  \"\n",
    "txt = \"  Clima   caluroso    llamen a  EmErGeNcias\"\n",
    "sea = \"welcome to redistribute livig  N\"\n",
    "\n",
    "print(\"Ej1 preserve:\", normalize_whitespace(s))\n",
    "print(\"Ej1 lower:   \", normalize_whitespace(s, case='lower'))\n",
    "print(\"Ej1 title:   \", normalize_whitespace(s, case='title'))\n",
    "print(\"Ej1 sentence:\", normalize_whitespace(s, case='sentence'))\n",
    "\n",
    "print(\"Ej2 preserve:\", normalize_whitespace(txt))\n",
    "print(\"Ej2 lower:   \", normalize_whitespace(txt, case='lower'))\n",
    "print(\"Ej2 sentence:\", normalize_whitespace(txt, case='sentence'))\n",
    "\n",
    "print(\"Ej3 preserve:\", normalize_whitespace(sea))\n",
    "print(\"Ej3 lower:   \", normalize_whitespace(sea, case='lower'))\n",
    "print(\"Ej3 title:   \", normalize_whitespace(sea, case='title'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7c6c55",
   "metadata": {},
   "source": [
    "# Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "344825cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_unique(*lists):\n",
    "    \"\"\"\n",
    "    Receives an unspecified number of lists and returns\n",
    "    a list with all unique elements.\n",
    "    \"\"\"\n",
    "    unique = set()\n",
    "    for lst in lists:\n",
    "        unique.update(lst)\n",
    "    return list(unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d809be77",
   "metadata": {},
   "source": [
    "### Using merge_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2295bc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 3, 4]\n",
    "b = [3, 4, 5, 6]\n",
    "c = [6, 7, 8]\n",
    "\n",
    "print(merge_unique(a, b, c))\n",
    "\n",
    "\n",
    "a = [\"Pear\",\"Apple\",\"Watermelon\"]\n",
    "b = [\"Pineapple\",\"Pear\",\"Banana\", \"Apple\", \"Pear\"]\n",
    "c = [\"Watermelon\",\"Pineapple\",\"Pear\",\"Banana\"]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
